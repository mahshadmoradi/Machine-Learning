{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Introduction to Machine Learning - Course Code: 25737</h1>\n",
    "<h4 align=\"center\">Instructor: Dr. Amiri</h4>\n",
    "<h4 align=\"center\">Sharif University of Technology, Spring 2024</h4>\n",
    "<h4 align=\"center\">Computer Assignment 3</h4>\n",
    "<h4 align=\"center\">\n",
    "\n",
    "Question 2\n",
    "\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your student number\n",
    "student_number = \n",
    "Name = ''\n",
    "Last_Name = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rules\n",
    "- You are not allowed to add or remove cells. You **must use the provided space to write your code**. If you don't follow this rule, **your Practical Assignment won't be graded**.  \n",
    "\n",
    "- Collaboration and using the internet is allowed, but your code **must be written by yourself**. **Copying code** from each other or from available resources will result in a **zero score for the assignment**.\n",
    "\n",
    "- You are not allowed to use `torch.nn`, `torch.optim` and any activation function and loss function implemented in torch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1) Convolutional Neural Networks ``(50 pt.)``\n",
    "\n",
    "In this question, you'll be coding up a convolutional neural network from scratch to classify images using PyTorch.  \n",
    "\n",
    "### Instructions\n",
    "- Install PyTorch following the instructions [here](https://pytorch.org/).\n",
    "- Install the [`torchinfo` package](https://github.com/TylerYep/torchinfo) to visualize the network architecture and the number of parameters. The maximum number of parameters you are allowed to use for your network is **100,000**. \n",
    "- You are required to complete the functions defined in the code blocks following each question. Fill out sections of the code marked `\"YOUR CODE HERE\"`.\n",
    "- You're free to add any number of methods within each class.\n",
    "- You may also add any number of additional code blocks that you deem necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "In this assignment, we will use the Fashion-MNIST dataset. Fashion-MNIST is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.  \n",
    "\n",
    "#### Data\n",
    "\n",
    "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255.  \n",
    "\n",
    "#### Labels\n",
    "\n",
    "Each training and test example is assigned to one of the following labels:\n",
    "\n",
    "| Label | Description |\n",
    "|-------|-------------|\n",
    "| 0     | T-shirt/top |\n",
    "| 1     | Trouser     |\n",
    "| 2     | Pullover    |\n",
    "| 3     | Dress       |\n",
    "| 4     | Coat        |\n",
    "| 5     | Sandal      |\n",
    "| 6     | Shirt       |\n",
    "| 7     | Sneaker     |\n",
    "| 8     | Bag         |\n",
    "| 9     | Ankle boot  |\n",
    "\n",
    "Fashion-MNIST is included in the `torchvision` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to normalize the data and convert to a tensor\n",
    "transform = Compose([ToTensor(), Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Download the data\n",
    "dataset = FashionMNIST('MNIST_data/', download = True, train = True, transform = transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "Let's take a look at the classes in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, visualize an instance from each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "#   YOUR CODE HERE   #\n",
    "######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Training and Validation Datasets\n",
    "\n",
    "The `split_indices` function takes in the size of the entire dataset, `n`, the fraction of data to be used as validation set, `val_frac`, and the random seed and returns the indices of the data points to be added to the validation dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_indices(n, val_frac, seed):\n",
    "    # Determine the size of the validation set\n",
    "    n_val = int(val_frac * n)\n",
    "    np.random.seed(seed)\n",
    "    # Create random permutation between 0 to n-1\n",
    "    idxs = np.random.permutation(n)\n",
    "    # Pick first n_val indices for validation set\n",
    "    return idxs[n_val:], idxs[:n_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "#   YOUR CODE HERE   #\n",
    "######################\n",
    "val_frac =  ## Set the fraction for the validation set\n",
    "rand_seed =  ## Set the random seed\n",
    "\n",
    "train_indices, val_indices = split_indices(len(dataset), val_frac, rand_seed)\n",
    "print(\"number of samples in training set: {}\".format(len(train_indices)))\n",
    "print(\"number of samples in validation set: {}\".format(len(val_indices)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we make use of the built-in dataloaders in PyTorch to create iterables of our our training and validation sets. This helps in avoiding fitting the whole dataset into memory and only loads a batch of the data that we can decide. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "#   YOUR CODE HERE   #\n",
    "######################\n",
    "batch_size = ## Set the batch size\n",
    "\n",
    "# Training sampler and data loader\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "train_dl = DataLoader(dataset,\n",
    "                     batch_size,\n",
    "                     sampler=train_sampler)\n",
    "\n",
    "# Validation sampler and data loader\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "val_dl = DataLoader(dataset,\n",
    "                   batch_size,\n",
    "                   sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot images in a sample batch of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "#   YOUR CODE HERE   #\n",
    "######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Model\n",
    "Create your model by defining the network architecture in the `ImageClassifierNet` class.<br>\n",
    "**NOTE:** The number of parameters in your network must be $\\leq$ 100,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifierNet(nn.Module):\n",
    "    def __init__(self, n_channels=3):\n",
    "        super(ImageClassifierNet, self).__init__()\n",
    "        ######################\n",
    "        #   YOUR CODE HERE   #\n",
    "        ######################\n",
    "        \n",
    "    def forward(self, X):\n",
    "        ######################\n",
    "        #   YOUR CODE HERE   #\n",
    "        ######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImageClassifierNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block prints your network architecture. It also shows the total number of parameters in your network (see `Total params`).  \n",
    "\n",
    "**NOTE: The total number of parameters in your model should be <= 100,000.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, input_size=(batch_size, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "Complete the `train_model` function to train your model on a dataset. Tune your network architecture and hyperparameters on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(n_epochs, model, train_dl, val_dl, loss_fn, opt_fn, lr):\n",
    "    \"\"\"\n",
    "    Trains the model on a dataset.\n",
    "    \n",
    "    Args:\n",
    "        n_epochs: number of epochs\n",
    "        model: ImageClassifierNet object\n",
    "        train_dl: training dataloader\n",
    "        val_dl: validation dataloader\n",
    "        loss_fn: the loss function\n",
    "        opt_fn: the optimizer\n",
    "        lr: learning rate\n",
    "    \n",
    "    Returns:\n",
    "        The trained model. \n",
    "        A tuple of (model, train_losses, val_losses, train_accuracies, val_accuracies)\n",
    "    \"\"\"\n",
    "    # Record these values the end of each epoch\n",
    "    train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []\n",
    "    \n",
    "    ######################\n",
    "    #   YOUR CODE HERE   #\n",
    "    ######################\n",
    "    \n",
    "    return model, train_losses, val_losses, train_accuracies, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "#   YOUR CODE HERE   #\n",
    "######################\n",
    "num_epochs = # Number of training epochs\n",
    "loss_fn =  # Define the loss function\n",
    "opt_fn =  # Select an optimizer\n",
    "lr =  # Set the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, train_losses, val_losses, train_accuracies, val_accuracies = train_model(num_epochs, model, train_dl, val_dl, loss_fn, opt_fn, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(train_accuracies, val_accuracies):\n",
    "    \"\"\"Plot accuracies\"\"\"\n",
    "    plt.plot(train_accuracies, \"-x\")\n",
    "    plt.plot(val_accuracies, \"-o\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend([\"Training\", \"Validation\"])\n",
    "    plt.title(\"Accuracy vs. No. of epochs\")\n",
    "\n",
    "def plot_losses(train_losses, val_losses):\n",
    "    \"\"\"Plot losses\"\"\"\n",
    "    plt.plot(train_losses, \"-x\")\n",
    "    plt.plot(val_losses, \"-o\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend([\"Training\", \"Validation\"])\n",
    "    plt.title(\"Loss vs. No. of Epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(train_accuracies, val_accuracies)\n",
    "plot_losses(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model on the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices, _ = split_indices(len(dataset), 0, rand_seed)\n",
    "\n",
    "sampler = SubsetRandomSampler(indices)\n",
    "dl = DataLoader(dataset, batch_size, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "#   YOUR CODE HERE   #\n",
    "######################\n",
    "num_epochs = # Max number of training epochs\n",
    "lr = # Set the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _, _, _, _ = train_model(num_epochs, model, dl, [], loss_fn, opt_fn, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Predictions\n",
    "Now, you should evaluate your model on dataset. Specifically, you should calculate the class probabilities for each image, and then visualize these probabilities along with the image itself. Please include a function `view_prediction` in your code that takes an image, its label, the calculated probabilities, and the list of class names as input, and plots the image along with the probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "#   YOUR CODE HERE   #\n",
    "######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate accuracy on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = FashionMNIST('MNIST_data/', download = True, train = False, transform = transform)\n",
    "test_dl = DataLoader(test_dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_dl):\n",
    "    \"\"\"\n",
    "    Evaluates your model on the test data.\n",
    "    \n",
    "    Args:\n",
    "        model: ImageClassifierNet object\n",
    "        test_dl: test dataloader\n",
    "    \n",
    "    Returns: \n",
    "        Test accuracy.\n",
    "    \"\"\"\n",
    "    ######################\n",
    "    #   YOUR CODE HERE   #\n",
    "    ######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Accuracy = {:.4f}\".format(evaluate(model, test_dl)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
